{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that I will use to transfer integer to one_hot array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#function that transform integer to one_hot array\n",
    "def one_hot(input_data):\n",
    "    one_hot = []\n",
    "    for item in input_data:\n",
    "        if item == 0.:\n",
    "            one_h = [1.,0.,0.,0.,0.]\n",
    "        elif item == 1.:\n",
    "            one_h = [0.,1.,0.,0.,0.]\n",
    "        elif item == 2.:\n",
    "            one_h = [0.,0.,1.,0.,0.]\n",
    "        elif item == 3.:\n",
    "            one_h = [0.,0.,0.,1.,0.]\n",
    "        elif item == 4.:\n",
    "            one_h = [0.,0.,0.,0.,1.]\n",
    "\n",
    "        one_hot.append(one_h)\n",
    "    one_hot = np.array(one_hot)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 restore HW2 and train the softmax layer only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpointFile/my_test_model\n",
      "1\tValidation loss: 1.044013 \tAccuracy: 61.33%\n",
      "2\tValidation loss: 0.983115 \tAccuracy: 68.67%\n",
      "3\tValidation loss: 0.858689 \tAccuracy: 72.00%\n",
      "4\tValidation loss: 0.799455 \tAccuracy: 71.33%\n",
      "5\tValidation loss: 0.815953 \tAccuracy: 70.00%\n",
      "6\tValidation loss: 0.833939 \tAccuracy: 72.67%\n",
      "7\tValidation loss: 0.816728 \tAccuracy: 72.67%\n",
      "8\tValidation loss: 0.757690 \tAccuracy: 73.33%\n",
      "9\tValidation loss: 0.854479 \tAccuracy: 66.67%\n",
      "10\tValidation loss: 0.770712 \tAccuracy: 74.00%\n",
      "11\tValidation loss: 0.750588 \tAccuracy: 76.67%\n",
      "12\tValidation loss: 0.812793 \tAccuracy: 70.00%\n",
      "13\tValidation loss: 0.674246 \tAccuracy: 76.67%\n",
      "14\tValidation loss: 0.757171 \tAccuracy: 74.67%\n",
      "15\tValidation loss: 0.782226 \tAccuracy: 73.33%\n",
      "16\tValidation loss: 0.728165 \tAccuracy: 76.00%\n",
      "17\tValidation loss: 0.726828 \tAccuracy: 74.00%\n",
      "18\tValidation loss: 0.737237 \tAccuracy: 71.33%\n",
      "19\tValidation loss: 0.745196 \tAccuracy: 72.00%\n",
      "20\tValidation loss: 0.693489 \tAccuracy: 76.67%\n",
      "21\tValidation loss: 0.696381 \tAccuracy: 74.67%\n",
      "22\tValidation loss: 0.696064 \tAccuracy: 74.67%\n",
      "23\tValidation loss: 0.713377 \tAccuracy: 74.67%\n",
      "24\tValidation loss: 0.715593 \tAccuracy: 75.33%\n",
      "25\tValidation loss: 0.699589 \tAccuracy: 74.67%\n",
      "26\tValidation loss: 0.709868 \tAccuracy: 74.67%\n",
      "27\tValidation loss: 0.678342 \tAccuracy: 75.33%\n",
      "28\tValidation loss: 0.724059 \tAccuracy: 76.67%\n",
      "29\tValidation loss: 0.728677 \tAccuracy: 76.00%\n",
      "30\tValidation loss: 0.700207 \tAccuracy: 76.00%\n",
      "31\tValidation loss: 0.666569 \tAccuracy: 76.00%\n",
      "32\tValidation loss: 0.712596 \tAccuracy: 76.00%\n",
      "33\tValidation loss: 0.726915 \tAccuracy: 72.67%\n",
      "34\tValidation loss: 0.671042 \tAccuracy: 76.00%\n",
      "35\tValidation loss: 0.713446 \tAccuracy: 76.00%\n",
      "36\tValidation loss: 0.664756 \tAccuracy: 78.00%\n",
      "37\tValidation loss: 0.794319 \tAccuracy: 68.67%\n",
      "38\tValidation loss: 0.778675 \tAccuracy: 73.33%\n",
      "39\tValidation loss: 0.725460 \tAccuracy: 74.00%\n",
      "40\tValidation loss: 0.699404 \tAccuracy: 74.67%\n",
      "41\tValidation loss: 0.660016 \tAccuracy: 78.00%\n",
      "42\tValidation loss: 0.667264 \tAccuracy: 78.00%\n",
      "43\tValidation loss: 0.709412 \tAccuracy: 76.00%\n",
      "44\tValidation loss: 0.695549 \tAccuracy: 75.33%\n",
      "45\tValidation loss: 0.638053 \tAccuracy: 75.33%\n",
      "46\tValidation loss: 0.730252 \tAccuracy: 76.00%\n",
      "47\tValidation loss: 0.629554 \tAccuracy: 76.67%\n",
      "48\tValidation loss: 0.682936 \tAccuracy: 76.00%\n",
      "49\tValidation loss: 0.708853 \tAccuracy: 75.33%\n",
      "50\tValidation loss: 0.732639 \tAccuracy: 72.67%\n",
      "51\tValidation loss: 0.781362 \tAccuracy: 75.33%\n",
      "52\tValidation loss: 0.721683 \tAccuracy: 75.33%\n",
      "53\tValidation loss: 0.792933 \tAccuracy: 68.00%\n",
      "54\tValidation loss: 0.693766 \tAccuracy: 75.33%\n",
      "55\tValidation loss: 0.705593 \tAccuracy: 72.67%\n",
      "56\tValidation loss: 0.726380 \tAccuracy: 74.00%\n",
      "57\tValidation loss: 0.698676 \tAccuracy: 73.33%\n",
      "58\tValidation loss: 0.669383 \tAccuracy: 78.00%\n",
      "59\tValidation loss: 0.859168 \tAccuracy: 71.33%\n",
      "60\tValidation loss: 0.705587 \tAccuracy: 76.00%\n",
      "61\tValidation loss: 0.722582 \tAccuracy: 76.00%\n",
      "62\tValidation loss: 0.698426 \tAccuracy: 77.33%\n",
      "63\tValidation loss: 0.669307 \tAccuracy: 77.33%\n",
      "64\tValidation loss: 0.721960 \tAccuracy: 76.00%\n",
      "65\tValidation loss: 0.690698 \tAccuracy: 74.00%\n",
      "66\tValidation loss: 0.656023 \tAccuracy: 75.33%\n",
      "67\tValidation loss: 0.780105 \tAccuracy: 75.33%\n",
      "Early stop after 67 epoches, best loss is 0.629554\n",
      "Training time is 51.147280 sec.\n",
      "INFO:tensorflow:Restoring parameters from ./Team46_HW3_1/Team46_HW3_1.ckpt\n",
      "Final test accuracy: 72.85%\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "training_epochs = 1000\n",
    "batch_size = 20\n",
    "train_data_size = np.prod(X_train2.shape[0]) \n",
    "total_batch = int(train_data_size/batch_size)\n",
    "\n",
    "# Training cycle\n",
    "current_best = 100.0\n",
    "stopping_step = 0\n",
    "epoch_number = 0\n",
    "  \n",
    "# First, load meta graph so that we can get the structure of HW2\n",
    "saver = tf.train.import_meta_graph('./checkpointFile/my_test_model.meta')\n",
    "\n",
    "# Now, let's access and load all the tensor and function that we need\n",
    "# :0 is the index of the tensor\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "x = graph.get_tensor_by_name(\"X:0\")\n",
    "true_labels = graph.get_tensor_by_name(\"TL:0\")\n",
    "dropout_keep_prob = graph.get_tensor_by_name(\"dropout:0\")\n",
    "loss = graph.get_tensor_by_name(\"loss:0\")\n",
    "accuracy = graph.get_tensor_by_name(\"accuracy:0\")\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"output\")\n",
    "Optimizer = tf.train.AdamOptimizer(0.01, name='Opt')\n",
    "train_op = Optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "five_frozen_saver = tf.train.Saver()\n",
    "\n",
    "# Transform true labels to one hot representation\n",
    "y_train2 = one_hot(y_train2)\n",
    "y_valid2 = one_hot(y_valid2)\n",
    "y_test2 = one_hot(y_test2)\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Load and restore HW2 checkpoint into sess\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpointFile/checkpoint'))\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    # Initialize the variable that will be trained\n",
    "    for var in output_layer_vars:\n",
    "        sess.run(var.initializer)\n",
    "\n",
    "    t0_3_1 = time.time()\n",
    "    for epoch in range(training_epochs):\n",
    "        epoch_number+=1\n",
    "\n",
    "        # Generate random indexes\n",
    "        indexes = np.random.permutation(train_data_size)\n",
    "\n",
    "        # Run all datas for one epoch\n",
    "        for position in range(0, train_data_size, batch_size):\n",
    "            # Generate mini batch ids\n",
    "            ids = indexes[position:(position+batch_size) if (position+batch_size) < train_data_size else train_data_size]\n",
    "            batch_xs = X_train2[ids]\n",
    "            batch_ts = y_train2[ids]\n",
    "            sess.run(train_op,feed_dict={x:batch_xs, true_labels:batch_ts, dropout_keep_prob: 1})\n",
    "\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],feed_dict={x:X_valid2, true_labels:y_valid2, dropout_keep_prob: 1})\n",
    "        \n",
    "        print(\"{}\\tValidation loss: {:.6f} \\tAccuracy: {:.2f}%\".format(epoch+1, loss_val, acc_val * 100))\n",
    "        if(loss_val < current_best):\n",
    "            # Save the best model so far into Team46_HW3_1 checkpoint\n",
    "            save_path = five_frozen_saver.save(sess, \"./Team46_HW3_1/Team46_HW3_1.ckpt\")\n",
    "            current_best = loss_val\n",
    "            stopping_step = 0\n",
    "        else:\n",
    "            stopping_step +=1\n",
    "\n",
    "        if(stopping_step >= 20):\n",
    "            break\n",
    "\n",
    "    print ('Early stop after %d epoches, best loss is %f'% (epoch_number,current_best))\n",
    "    t1_3_1 = time.time()\n",
    "    print ('Training time is %f sec.'% (t1_3_1-t0_3_1))\n",
    "    \n",
    "# Restore Team46_HW3_1 checkpoint and test the model\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team46_HW3_1/Team46_HW3_1.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={x: X_test2, true_labels: y_test2, dropout_keep_prob: 1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 restore HW2 and cache 5th layer before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpointFile/my_test_model\n",
      "1\tValidation loss: 1.027873 \tAccuracy: 64.00%\n",
      "2\tValidation loss: 0.937901 \tAccuracy: 64.00%\n",
      "3\tValidation loss: 0.906457 \tAccuracy: 70.00%\n",
      "4\tValidation loss: 0.820263 \tAccuracy: 68.00%\n",
      "5\tValidation loss: 0.796498 \tAccuracy: 70.67%\n",
      "6\tValidation loss: 0.870613 \tAccuracy: 64.67%\n",
      "7\tValidation loss: 0.773138 \tAccuracy: 69.33%\n",
      "8\tValidation loss: 0.750011 \tAccuracy: 72.67%\n",
      "9\tValidation loss: 0.809875 \tAccuracy: 71.33%\n",
      "10\tValidation loss: 0.843827 \tAccuracy: 68.67%\n",
      "11\tValidation loss: 0.744980 \tAccuracy: 75.33%\n",
      "12\tValidation loss: 0.767153 \tAccuracy: 73.33%\n",
      "13\tValidation loss: 0.782638 \tAccuracy: 73.33%\n",
      "14\tValidation loss: 0.750746 \tAccuracy: 75.33%\n",
      "15\tValidation loss: 0.700559 \tAccuracy: 75.33%\n",
      "16\tValidation loss: 0.796858 \tAccuracy: 72.67%\n",
      "17\tValidation loss: 0.730536 \tAccuracy: 75.33%\n",
      "18\tValidation loss: 0.792971 \tAccuracy: 73.33%\n",
      "19\tValidation loss: 0.701393 \tAccuracy: 75.33%\n",
      "20\tValidation loss: 0.699928 \tAccuracy: 76.67%\n",
      "21\tValidation loss: 0.739568 \tAccuracy: 75.33%\n",
      "22\tValidation loss: 0.804570 \tAccuracy: 73.33%\n",
      "23\tValidation loss: 0.731305 \tAccuracy: 74.00%\n",
      "24\tValidation loss: 0.680910 \tAccuracy: 77.33%\n",
      "25\tValidation loss: 0.735119 \tAccuracy: 76.67%\n",
      "26\tValidation loss: 0.792361 \tAccuracy: 73.33%\n",
      "27\tValidation loss: 0.784174 \tAccuracy: 74.00%\n",
      "28\tValidation loss: 0.769462 \tAccuracy: 74.67%\n",
      "29\tValidation loss: 0.667907 \tAccuracy: 76.67%\n",
      "30\tValidation loss: 0.728527 \tAccuracy: 74.00%\n",
      "31\tValidation loss: 0.694613 \tAccuracy: 75.33%\n",
      "32\tValidation loss: 0.716236 \tAccuracy: 72.67%\n",
      "33\tValidation loss: 0.751426 \tAccuracy: 74.67%\n",
      "34\tValidation loss: 0.654036 \tAccuracy: 76.67%\n",
      "35\tValidation loss: 0.685032 \tAccuracy: 78.67%\n",
      "36\tValidation loss: 0.721836 \tAccuracy: 74.67%\n",
      "37\tValidation loss: 0.688465 \tAccuracy: 77.33%\n",
      "38\tValidation loss: 0.698641 \tAccuracy: 75.33%\n",
      "39\tValidation loss: 0.659301 \tAccuracy: 78.00%\n",
      "40\tValidation loss: 0.647456 \tAccuracy: 78.00%\n",
      "41\tValidation loss: 0.643831 \tAccuracy: 78.00%\n",
      "42\tValidation loss: 0.697119 \tAccuracy: 76.00%\n",
      "43\tValidation loss: 0.730279 \tAccuracy: 74.00%\n",
      "44\tValidation loss: 0.688342 \tAccuracy: 75.33%\n",
      "45\tValidation loss: 0.650898 \tAccuracy: 78.00%\n",
      "46\tValidation loss: 0.685356 \tAccuracy: 78.00%\n",
      "47\tValidation loss: 0.718144 \tAccuracy: 74.00%\n",
      "48\tValidation loss: 0.664264 \tAccuracy: 78.00%\n",
      "49\tValidation loss: 0.671177 \tAccuracy: 78.67%\n",
      "50\tValidation loss: 0.654037 \tAccuracy: 76.00%\n",
      "51\tValidation loss: 0.765692 \tAccuracy: 71.33%\n",
      "52\tValidation loss: 0.703111 \tAccuracy: 76.67%\n",
      "53\tValidation loss: 0.687327 \tAccuracy: 73.33%\n",
      "54\tValidation loss: 0.677333 \tAccuracy: 78.00%\n",
      "55\tValidation loss: 0.677046 \tAccuracy: 76.67%\n",
      "56\tValidation loss: 0.707019 \tAccuracy: 75.33%\n",
      "57\tValidation loss: 0.676952 \tAccuracy: 73.33%\n",
      "58\tValidation loss: 0.664775 \tAccuracy: 76.67%\n",
      "59\tValidation loss: 0.748855 \tAccuracy: 74.67%\n",
      "60\tValidation loss: 0.692200 \tAccuracy: 76.00%\n",
      "61\tValidation loss: 0.637641 \tAccuracy: 77.33%\n",
      "62\tValidation loss: 0.731748 \tAccuracy: 76.00%\n",
      "63\tValidation loss: 0.688861 \tAccuracy: 76.67%\n",
      "64\tValidation loss: 0.758772 \tAccuracy: 74.00%\n",
      "65\tValidation loss: 0.694511 \tAccuracy: 78.00%\n",
      "66\tValidation loss: 0.683082 \tAccuracy: 76.67%\n",
      "67\tValidation loss: 0.780721 \tAccuracy: 76.67%\n",
      "68\tValidation loss: 0.712172 \tAccuracy: 76.67%\n",
      "69\tValidation loss: 0.692913 \tAccuracy: 76.00%\n",
      "70\tValidation loss: 0.684627 \tAccuracy: 76.00%\n",
      "71\tValidation loss: 0.779054 \tAccuracy: 72.00%\n",
      "72\tValidation loss: 0.742642 \tAccuracy: 75.33%\n",
      "73\tValidation loss: 0.735606 \tAccuracy: 74.67%\n",
      "74\tValidation loss: 0.731929 \tAccuracy: 72.67%\n",
      "75\tValidation loss: 0.715028 \tAccuracy: 74.00%\n",
      "76\tValidation loss: 0.859050 \tAccuracy: 75.33%\n",
      "77\tValidation loss: 0.662335 \tAccuracy: 77.33%\n",
      "78\tValidation loss: 0.692824 \tAccuracy: 74.67%\n",
      "79\tValidation loss: 0.764267 \tAccuracy: 72.67%\n",
      "80\tValidation loss: 0.927735 \tAccuracy: 68.00%\n",
      "81\tValidation loss: 0.671993 \tAccuracy: 75.33%\n",
      "Early stop after 81 epoches, best loss is 0.637641\n",
      "Training time is 61.812149 sec.\n",
      "INFO:tensorflow:Restoring parameters from ./Team46_HW3_2/Team46_HW3_2.ckpt\n",
      "Final test accuracy: 72.64%\n"
     ]
    }
   ],
   "source": [
    "# Get layer5 of HW2\n",
    "layer5 = graph.get_tensor_by_name(\"Layer5:0\")\n",
    "\n",
    "# Training cycle\n",
    "current_best = 100.0\n",
    "stopping_step = 0\n",
    "epoch_number = 0\n",
    "cache_five_frozen_saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpointFile/checkpoint'))\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for var in output_layer_vars:\n",
    "        sess.run(var.initializer)\n",
    "    \n",
    "    # Feed X_train2 and X_valid2 into layer5 before training to accelerate \n",
    "    layer5_train = layer5.eval(feed_dict={x:X_train2})\n",
    "    layer5_valid = layer5.eval(feed_dict={x:X_valid2})\n",
    "    \n",
    "    t0_3_2 = time.time()\n",
    "    for epoch in range(training_epochs):\n",
    "        epoch_number+=1\n",
    "\n",
    "        # Generate random indexes\n",
    "        indexes = np.random.permutation(train_data_size)\n",
    "\n",
    "        # Run all datas for one epoch\n",
    "        for position in range(0, train_data_size, batch_size):\n",
    "            # Generate mini batch ids\n",
    "            ids = indexes[position:(position+batch_size) if (position+batch_size) < train_data_size else train_data_size]\n",
    "            batch_xs = layer5_train[ids]\n",
    "            batch_ts = y_train2[ids]\n",
    "            # Feed layer5 into training process \n",
    "            sess.run(train_op,feed_dict={layer5:batch_xs, true_labels:batch_ts, dropout_keep_prob: 1})\n",
    "\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],feed_dict={layer5:layer5_valid, true_labels:y_valid2, dropout_keep_prob: 1})\n",
    "\n",
    "        print(\"{}\\tValidation loss: {:.6f} \\tAccuracy: {:.2f}%\".format(epoch+1, loss_val, acc_val * 100))\n",
    "        if(loss_val < current_best):\n",
    "            save_path = five_frozen_saver.save(sess, \"./Team46_HW3_2/Team46_HW3_2.ckpt\")\n",
    "            current_best = loss_val\n",
    "            stopping_step = 0\n",
    "        else:\n",
    "            stopping_step +=1\n",
    "\n",
    "        if(stopping_step >= 20):\n",
    "            break\n",
    "\n",
    "    print ('Early stop after %d epoches, best loss is %f'% (epoch_number,current_best))\n",
    "    t1_3_2 = time.time()\n",
    "    print ('Training time is %f sec.'% (t1_3_2-t0_3_2))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    cache_five_frozen_saver.restore(sess, \"./Team46_HW3_2/Team46_HW3_2.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={x: X_test2, true_labels: y_test2, dropout_keep_prob: 1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Train 4 layers instead and add new softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpointFile/my_test_model\n",
      "1\tValidation loss: 0.928629 \tAccuracy: 63.33%\n",
      "2\tValidation loss: 0.799891 \tAccuracy: 72.67%\n",
      "3\tValidation loss: 0.784990 \tAccuracy: 75.33%\n",
      "4\tValidation loss: 0.706666 \tAccuracy: 78.00%\n",
      "5\tValidation loss: 0.669182 \tAccuracy: 78.67%\n",
      "6\tValidation loss: 0.682850 \tAccuracy: 79.33%\n",
      "7\tValidation loss: 0.669138 \tAccuracy: 77.33%\n",
      "8\tValidation loss: 0.722017 \tAccuracy: 72.00%\n",
      "9\tValidation loss: 0.697509 \tAccuracy: 75.33%\n",
      "10\tValidation loss: 0.664611 \tAccuracy: 78.67%\n",
      "11\tValidation loss: 0.687688 \tAccuracy: 74.67%\n",
      "12\tValidation loss: 0.645189 \tAccuracy: 76.00%\n",
      "13\tValidation loss: 0.680613 \tAccuracy: 78.00%\n",
      "14\tValidation loss: 0.645354 \tAccuracy: 79.33%\n",
      "15\tValidation loss: 0.704536 \tAccuracy: 73.33%\n",
      "16\tValidation loss: 0.670711 \tAccuracy: 76.67%\n",
      "17\tValidation loss: 0.746355 \tAccuracy: 74.67%\n",
      "18\tValidation loss: 0.697532 \tAccuracy: 71.33%\n",
      "19\tValidation loss: 0.693980 \tAccuracy: 76.00%\n",
      "20\tValidation loss: 0.687959 \tAccuracy: 78.00%\n",
      "21\tValidation loss: 0.703708 \tAccuracy: 74.67%\n",
      "22\tValidation loss: 0.631665 \tAccuracy: 78.00%\n",
      "23\tValidation loss: 0.618662 \tAccuracy: 78.00%\n",
      "24\tValidation loss: 0.659194 \tAccuracy: 75.33%\n",
      "25\tValidation loss: 0.767403 \tAccuracy: 70.00%\n",
      "26\tValidation loss: 0.697706 \tAccuracy: 76.67%\n",
      "27\tValidation loss: 0.693001 \tAccuracy: 76.67%\n",
      "28\tValidation loss: 0.783403 \tAccuracy: 71.33%\n",
      "29\tValidation loss: 0.629589 \tAccuracy: 80.00%\n",
      "30\tValidation loss: 0.667746 \tAccuracy: 78.00%\n",
      "31\tValidation loss: 0.648356 \tAccuracy: 78.00%\n",
      "32\tValidation loss: 0.611663 \tAccuracy: 78.00%\n",
      "33\tValidation loss: 0.651747 \tAccuracy: 77.33%\n",
      "34\tValidation loss: 0.639365 \tAccuracy: 78.67%\n",
      "35\tValidation loss: 0.679810 \tAccuracy: 78.00%\n",
      "36\tValidation loss: 0.673080 \tAccuracy: 76.67%\n",
      "37\tValidation loss: 0.627642 \tAccuracy: 78.67%\n",
      "38\tValidation loss: 0.617268 \tAccuracy: 77.33%\n",
      "39\tValidation loss: 0.693460 \tAccuracy: 76.00%\n",
      "40\tValidation loss: 0.643382 \tAccuracy: 77.33%\n",
      "41\tValidation loss: 0.684335 \tAccuracy: 76.00%\n",
      "42\tValidation loss: 0.648379 \tAccuracy: 79.33%\n",
      "43\tValidation loss: 0.631388 \tAccuracy: 78.00%\n",
      "44\tValidation loss: 0.658625 \tAccuracy: 78.00%\n",
      "45\tValidation loss: 0.651200 \tAccuracy: 78.67%\n",
      "46\tValidation loss: 0.622978 \tAccuracy: 78.67%\n",
      "47\tValidation loss: 0.706240 \tAccuracy: 76.67%\n",
      "48\tValidation loss: 0.625518 \tAccuracy: 78.00%\n",
      "49\tValidation loss: 0.693232 \tAccuracy: 76.67%\n",
      "50\tValidation loss: 0.658782 \tAccuracy: 77.33%\n",
      "51\tValidation loss: 0.678128 \tAccuracy: 78.00%\n",
      "52\tValidation loss: 0.670169 \tAccuracy: 76.00%\n",
      "Early stop after 52 epoches, best loss is 0.611663\n",
      "Training time is 49.978062 sec.\n",
      "INFO:tensorflow:Restoring parameters from ./Team46_HW3_3/Team46_HW3_3.ckpt\n",
      "Final test accuracy: 38.00%\n"
     ]
    }
   ],
   "source": [
    "# Get layer4 of HW2\n",
    "layer4 = graph.get_tensor_by_name(\"Layer4:0\")\n",
    "\n",
    "# Training cycle\n",
    "current_best = 100.0\n",
    "stopping_step = 0\n",
    "epoch_number = 0\n",
    "\n",
    "OUTPUT_NODE = 5\n",
    "\n",
    "# Since the structure of our new model is different form HW2, we should define our new output layer,\n",
    "# loss&accuracy function, and optimizer ourselves.\n",
    "initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_AVG', uniform=True)\n",
    "\n",
    "output_3 = tf.layers.dense(inputs=layer4, units=OUTPUT_NODE, kernel_initializer=initializer, name='output_3')\n",
    "output_after_softmax_3 = tf.nn.softmax(output_3, name='output_after_softmax_3')\n",
    "\n",
    "loss_3 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits= output_3,labels= tf.argmax(true_labels, 1)), name='loss_3')\n",
    "correct_prediction_3 = tf.equal(tf.argmax(output_after_softmax_3, 1), tf.argmax(true_labels, 1))\n",
    "accuracy_3 = tf.reduce_mean(tf.cast(correct_prediction_3, tf.float32), name='accuracy_3')\n",
    "\n",
    "output_layer_vars_3 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"output_3\")\n",
    "Optimizer_3 = tf.train.AdamOptimizer(0.01, name='Opt_3')\n",
    "train_op_3 = Optimizer_3.minimize(loss_3, var_list=output_layer_vars_3)\n",
    "\n",
    "four_frozen_saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpointFile/checkpoint'))\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for var in output_layer_vars_3:\n",
    "        sess.run(var.initializer)\n",
    "    \n",
    "    # We cache 4th layer of HW2 to accelerate the training process.\n",
    "    # We can do this because the first four layers of the new model is the same as which in HW2.\n",
    "    layer4_train = layer4.eval(feed_dict={x:X_train2,true_labels:y_train2})\n",
    "    layer4_valid = layer4.eval(feed_dict={x:X_valid2,true_labels:y_train2})\n",
    "    \n",
    "    t0_3_3 = time.time()\n",
    "    for epoch in range(training_epochs):\n",
    "        epoch_number+=1\n",
    "\n",
    "        # Generate random indexes\n",
    "        indexes = np.random.permutation(train_data_size)\n",
    "\n",
    "        # Run all datas for one epoch\n",
    "        for position in range(0, train_data_size, batch_size):\n",
    "            # Generate mini batch ids\n",
    "            ids = indexes[position:(position+batch_size) if (position+batch_size) < train_data_size else train_data_size]\n",
    "            batch_xs = layer4_train[ids]\n",
    "            batch_ts = y_train2[ids]\n",
    "            # Feed layer4 into training process\n",
    "            sess.run(train_op_3,feed_dict={layer4:batch_xs, true_labels:batch_ts, dropout_keep_prob: 1})\n",
    "\n",
    "        loss_val, acc_val = sess.run([loss_3, accuracy_3],feed_dict={layer4:layer4_valid, true_labels:y_valid2, dropout_keep_prob: 1})\n",
    "\n",
    "        print(\"{}\\tValidation loss: {:.6f} \\tAccuracy: {:.2f}%\".format(epoch+1, loss_val, acc_val * 100))\n",
    "        if(loss_val < current_best):\n",
    "            save_path = four_frozen_saver.save(sess, \"./Team46_HW3_3/Team46_HW3_3.ckpt\")\n",
    "            current_best = loss_val\n",
    "            stopping_step = 0\n",
    "        else:\n",
    "            stopping_step +=1\n",
    "\n",
    "        if(stopping_step >= 20):\n",
    "            break\n",
    "\n",
    "    print ('Early stop after %d epoches, best loss is %f'% (epoch_number,current_best))\n",
    "    t1_3_3 = time.time()\n",
    "    print ('Training time is %f sec.'% (t1_3_3-t0_3_3))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./Team46_HW3_3/Team46_HW3_3.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={x: X_test2, true_labels: y_test2, dropout_keep_prob: 1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Base on 3.3 but freeze only layer3 and layer4 while making layer1 and layer2 trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpointFile/my_test_model\n",
      "1\tValidation loss: 0.438192 \tAccuracy: 87.33%\n",
      "2\tValidation loss: 0.371540 \tAccuracy: 90.67%\n",
      "3\tValidation loss: 0.471534 \tAccuracy: 90.00%\n",
      "4\tValidation loss: 0.548758 \tAccuracy: 88.00%\n",
      "5\tValidation loss: 0.523636 \tAccuracy: 90.67%\n",
      "6\tValidation loss: 0.584493 \tAccuracy: 90.00%\n",
      "7\tValidation loss: 0.574390 \tAccuracy: 86.67%\n",
      "8\tValidation loss: 0.569987 \tAccuracy: 93.33%\n",
      "9\tValidation loss: 0.514868 \tAccuracy: 92.00%\n",
      "10\tValidation loss: 0.787381 \tAccuracy: 86.00%\n",
      "11\tValidation loss: 0.654636 \tAccuracy: 90.67%\n",
      "12\tValidation loss: 0.658456 \tAccuracy: 92.67%\n",
      "13\tValidation loss: 0.687839 \tAccuracy: 92.67%\n",
      "14\tValidation loss: 0.621362 \tAccuracy: 92.67%\n",
      "15\tValidation loss: 0.613981 \tAccuracy: 92.67%\n",
      "16\tValidation loss: 0.613642 \tAccuracy: 92.67%\n",
      "17\tValidation loss: 0.612441 \tAccuracy: 92.67%\n",
      "18\tValidation loss: 0.613361 \tAccuracy: 92.67%\n",
      "19\tValidation loss: 0.614865 \tAccuracy: 92.67%\n",
      "20\tValidation loss: 0.615448 \tAccuracy: 92.67%\n",
      "21\tValidation loss: 0.616032 \tAccuracy: 92.67%\n",
      "22\tValidation loss: 0.616328 \tAccuracy: 92.67%\n",
      "Early stop after 22 epoches, best loss is 0.371540\n",
      "Training time is 9.695843 sec.\n",
      "INFO:tensorflow:Restoring parameters from ./Team46_HW3_4/Team46_HW3_4.ckpt\n",
      "Final test accuracy: 17.75%\n"
     ]
    }
   ],
   "source": [
    "# Get TRAINABLE_VARIABLES within scope output_3 or Layer1 or Layer2\n",
    "output_layer_vars_4 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"output_3|Layer1|Layer2\")\n",
    "\n",
    "# Feed new vaberiable set into new optimizer\n",
    "Optimizer = tf.train.AdamOptimizer(0.01, name='Opt_4')\n",
    "train_op = Optimizer.minimize(loss_3, var_list=output_layer_vars_4)\n",
    "\n",
    "two_frozen_saver = tf.train.Saver()\n",
    "\n",
    "# Training cycle\n",
    "current_best = 100.0\n",
    "stopping_step = 0\n",
    "epoch_number = 0\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('./checkpointFile/checkpoint'))\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for var in output_layer_vars_4:\n",
    "        sess.run(var.initializer)\n",
    "    \n",
    "    t0_3_4 = time.time()\n",
    "    for epoch in range(training_epochs):\n",
    "        epoch_number+=1\n",
    "\n",
    "        # Generate random indexes\n",
    "        indexes = np.random.permutation(train_data_size)\n",
    "\n",
    "        # Run all datas for one epoch\n",
    "        for position in range(0, train_data_size, batch_size):\n",
    "            # Generate mini batch ids\n",
    "            ids = indexes[position:(position+batch_size) if (position+batch_size) < train_data_size else train_data_size]\n",
    "            batch_xs = X_train2[ids]\n",
    "            batch_ts = y_train2[ids]\n",
    "            # We have to feed X_train2 into the train process and can not use cache since layer1 and lsayer2 are trainable\n",
    "            sess.run(train_op,feed_dict={x:batch_xs, true_labels:batch_ts, dropout_keep_prob: 1})\n",
    "            \n",
    "        loss_val, acc_val = sess.run([loss_3, accuracy_3],feed_dict={x:X_valid2, true_labels:y_valid2, dropout_keep_prob: 1})\n",
    "\n",
    "        print(\"{}\\tValidation loss: {:.6f} \\tAccuracy: {:.2f}%\".format(epoch+1, loss_val, acc_val * 100))\n",
    "        if(loss_val < current_best):\n",
    "            save_path = two_frozen_saver.save(sess, \"./Team46_HW3_4/Team46_HW3_4.ckpt\")\n",
    "            current_best = loss_val\n",
    "            stopping_step = 0\n",
    "        else:\n",
    "            stopping_step +=1\n",
    "\n",
    "        if(stopping_step >= 20):\n",
    "            break\n",
    "\n",
    "    print ('Early stop after %d epoches, best loss is %f'% (epoch_number,current_best))\n",
    "    t1_3_4 = time.time()\n",
    "    print ('Training time is %f sec.'% (t1_3_4-t0_3_4))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./Team46_HW3_4/Team46_HW3_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={x: X_test2, true_labels: y_test2, dropout_keep_prob: 1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
